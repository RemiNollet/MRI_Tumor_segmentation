{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3573fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "HGG_path = Path(os.path.expanduser(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/HGG/\"))\n",
    "LGG_path = Path(os.path.expanduser(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/LGG/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da355a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/60fb61/brats_2019.zip \n",
    "!unzip -q brats_2019.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2606b",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ef96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load NIfTI file\n",
    "img = nib.load(os.path.join(HGG_path, \"BraTS19_2013_2_1/BraTS19_2013_2_1_flair.nii\"))\n",
    "data = img.get_fdata()\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d72491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot a slice\n",
    "plt.imshow(data[:, :, 80], cmap=\"gray\") # coupe selon z=80 -> faire une video avec toutes les hauteurs? Couper selon les autres axes? \n",
    "plt.title(\"Middle slice of brain MRI\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = []\n",
    "\n",
    "# selectionner x patients au hasard\n",
    "x = 10\n",
    "patients = [p for p in HGG_path.iterdir() if p.is_dir()]\n",
    "sampled_patients = random.sample(patients, x)\n",
    "print(sampled_patients)\n",
    "\n",
    "# Boucle sur les x patients\n",
    "for patient in sampled_patients:\n",
    "    print(patient.name)\n",
    "    T1 = nib.load(f\"{HGG_path}/{patient.name}/{patient.name}_t1.nii\")\n",
    "    T1CE = nib.load(f\"{HGG_path}/{patient.name}/{patient.name}_t1ce.nii\")\n",
    "    T2 = nib.load(f\"{HGG_path}/{patient.name}/{patient.name}_t2.nii\")\n",
    "    FLAIR = nib.load(f\"{HGG_path}/{patient.name}/{patient.name}_flair.nii\")\n",
    "    SEG = nib.load(f\"{HGG_path}/{patient.name}/{patient.name}_seg.nii\")\n",
    "    imgs.append([T1, T1CE, T2, FLAIR, SEG])\n",
    "\n",
    "\n",
    "# Plot a slice\n",
    "fig, axes = plt.subplots(x, 5, figsize=(20, x*4))  # x rows, 5 columns\n",
    "\n",
    "for i, patient in enumerate(imgs):\n",
    "    for j, img in enumerate(patient):\n",
    "        data = img.get_fdata()\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(data[:, :, 80], cmap=\"gray\")\n",
    "        ax.set_title(f\"Patient {i+1} - Img {j+1}\")\n",
    "        ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14742f7",
   "metadata": {},
   "source": [
    "# Pre rocessing\n",
    "Nous avons des images en 240x240x155 et nous souhaitons les redimensionner en 240x240x144 (sans alterer les dimensions). \\\n",
    "Nous constatons que sur les grande majorite des images, le cerveau s'arrete a 147 pixels et commence a 3 pixels (sur l'axe z). \\\n",
    "Nous allons donc supprimer les 3 premieres couches ainsi que les 8 dernieres pour supprimer les couches vides et ainsi obtenir des parrallelepipedes de 240x240x144."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,:,3:147]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d5cf9",
   "metadata": {},
   "source": [
    "- Appliquer ce filtre sur toutes les images flair et segmentation \\\n",
    "- extraire toutes les images flair/seg redimensionnées dans un dossier sous la forme: \\\n",
    " dataset_UNET/ \\\n",
    " | \\\n",
    " |- X \\\n",
    " |   |- {patient_ID}_flair.nii  \\\n",
    " |   |... \\\n",
    " |- Y \\\n",
    " |   |- {patient_ID}_seg.nii  \\\n",
    " |   |... \\\n",
    " |- label.csv -> (patient_ID, grade) pour realiser la classification \\\n",
    "\\\n",
    "(- Regrouper les deux fichiers csv et ne garder que les colonnes: grade, ID_2019, age, survival, ResectionStatus)\\\n",
    "   -> Les fichiers csv sont ils utiles dans notre cas? Servent-ils uniquement dans un cas ou on souhaite entrainer \\\n",
    "   un model de ML pour faire de la predicitions de cancer ou autre, mais pas dans notre cas de detection de tumeur par computer vision? \n",
    "\\\n",
    "Le dossier dataset nous servira de base pour entrainer le model UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_X = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET/X\").expanduser()\n",
    "output_Y = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET/Y\").expanduser()\n",
    "\n",
    "output_X.mkdir(parents=True, exist_ok=True)\n",
    "output_Y.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "patients_HGG = [p for p in HGG_path.iterdir() if p.is_dir()]\n",
    "patients_LGG = [p for p in LGG_path.iterdir() if p.is_dir()]\n",
    "\n",
    "for patient in patients_HGG:\n",
    "    try:\n",
    "        flair_path = patient / f\"{patient.name}_flair.nii\"\n",
    "        seg_path   = patient / f\"{patient.name}_seg.nii\"\n",
    "\n",
    "        # Chargement et crop Z\n",
    "        flair_data = nib.load(flair_path).get_fdata()[:, :, 3:147]\n",
    "        seg_data   = nib.load(seg_path).get_fdata()[:, :, 3:147]\n",
    "\n",
    "        # Sauvegarde des .nii.gz cropped\n",
    "        flair_img = nib.Nifti1Image(flair_data, affine=np.eye(4))  # ajouter une affine minimale\n",
    "        seg_img   = nib.Nifti1Image(seg_data, affine=np.eye(4))\n",
    "\n",
    "        nib.save(flair_img, output_X / f\"{patient.name}_flair.nii.gz\")\n",
    "        nib.save(seg_img,   output_Y / f\"{patient.name}_seg.nii.gz\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec {patient.name}: {e}\")\n",
    "\n",
    "for patient in patients_LGG:\n",
    "    try:\n",
    "        flair_path = patient / f\"{patient.name}_flair.nii\"\n",
    "        seg_path   = patient / f\"{patient.name}_seg.nii\"\n",
    "\n",
    "        # Chargement et crop Z\n",
    "        flair_data = nib.load(flair_path).get_fdata()[:, :, 3:147]\n",
    "        seg_data   = nib.load(seg_path).get_fdata()[:, :, 3:147]\n",
    "\n",
    "        # Sauvegarde des .nii.gz cropped\n",
    "        flair_img = nib.Nifti1Image(flair_data, affine=np.eye(4))  # ajouter une affine minimale\n",
    "        seg_img   = nib.Nifti1Image(seg_data, affine=np.eye(4))\n",
    "\n",
    "        nib.save(flair_img, output_X / f\"{patient.name}_flair.nii.gz\")\n",
    "        nib.save(seg_img,   output_Y / f\"{patient.name}_seg.nii.gz\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec {patient.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7d940",
   "metadata": {},
   "source": [
    "## Save Dataset 2D dans un format .npy injectable dans tensorflow\n",
    "(Avec le dossier X contenant toutes les couches (suivant z) de toutes les images flair, et Y contenant toutes les couches de toutes les images seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "input_X = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET/X\").expanduser()\n",
    "input_Y = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET/Y\").expanduser()\n",
    "output_X = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET_2D/X\").expanduser()\n",
    "output_Y = Path(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET_2D/Y\").expanduser()\n",
    "\n",
    "output_X.mkdir(parents=True, exist_ok=True)\n",
    "output_Y.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for flair_file, seg_file in zip(input_X.glob(\"*.nii.gz\"), input_Y.glob(\"*.nii.gz\")):\n",
    "    patient_id_flair = flair_file.name.split(\"_flair\")[0]\n",
    "    patient_id_seg = seg_file.name.split(\"_seg\")[0]\n",
    "\n",
    "    flair_data = nib.load(flair_file).get_fdata()\n",
    "    seg_data = nib.load(seg_file).get_fdata()\n",
    "\n",
    "    # slice par axe Z\n",
    "    for i in range(flair_data.shape[2]):\n",
    "        img_slice = flair_data[:, :, i]\n",
    "        seg_slice = seg_data[:, :, i]\n",
    "\n",
    "        # Enregistrer slice 2D comme .npy\n",
    "        np.save(output_X / f\"{patient_id_flair}_slice_{i:03}.npy\", img_slice)\n",
    "        np.save(output_Y / f\"{patient_id_seg}_slice_{i:03}.npy\", seg_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e10e4f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42ec8a",
   "metadata": {},
   "source": [
    "## UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39478ee",
   "metadata": {},
   "source": [
    "### Creation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ba721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "X_paths = sorted(glob.glob(os.path.expanduser(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET_2D/X/*.npy\")))\n",
    "Y_paths = sorted(glob.glob(os.path.expanduser(\"~/CV_project_MRI/data/MICCAI_BraTS_2019_Data_Training/dataset_UNET_2D/Y/*.npy\")))\n",
    "\n",
    "def load_npy_pair(x_path, y_path):\n",
    "    x = np.load(x_path.decode()).astype(np.float32)\n",
    "    y = np.load(y_path.decode()).astype(np.float32)\n",
    "\n",
    "    # Normalisation min-max slice par slice\n",
    "    if x.max() > 0:  # éviter division par zéro\n",
    "        x = x / x.max()\n",
    "\n",
    "    x = np.expand_dims(x, axis=-1)  # (240, 240, 1)\n",
    "    y = np.expand_dims(y, axis=-1)\n",
    "    return x, y\n",
    "\n",
    "def tf_wrapper(x_path, y_path):\n",
    "    return tf.numpy_function(load_npy_pair, [x_path, y_path], [tf.float32, tf.float32])\n",
    "\n",
    "# Fonction de construction du dataset\n",
    "def make_dataset(data_pairs, batch_size=8):\n",
    "    X, Y = zip(*data_pairs)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((list(X), list(Y)))\n",
    "    ds = ds.map(tf_wrapper)\n",
    "    ds = ds.shuffle(100)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE) # pipeline asynchrone optimisé\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd64afb",
   "metadata": {},
   "source": [
    "### Creation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "def encoding_layer(input_layer,output_channels,kernel_size):\n",
    "    conv1 = Conv2D(output_channels, (kernel_size, kernel_size), activation='relu', padding='same',\\\n",
    "                   kernel_initializer=tf.random_normal_initializer(0, 0.02)) (input_layer)\n",
    "    return conv1\n",
    "\n",
    "def bottleneck(input_layer,output_channels,kernel_size):\n",
    "    bottleneck1 = Conv2D(output_channels, (kernel_size, kernel_size), activation='relu', padding='same',\\\n",
    "                         kernel_initializer=tf.random_normal_initializer(0, 0.02)) (input_layer)\n",
    "    bottleneck2 = Conv2D(output_channels, (kernel_size, kernel_size), activation='relu', padding='same',\\\n",
    "                         kernel_initializer=tf.random_normal_initializer(0, 0.02)) (bottleneck1)\n",
    "    return bottleneck2\n",
    "\n",
    "def decoding_layer(input_layer,skip_layer,output_channels,kernel_size,stride):\n",
    "    upconv1 = Conv2DTranspose(output_channels,  (kernel_size, kernel_size),strides=(stride,stride), padding='same',\\\n",
    "                              kernel_initializer=tf.random_normal_initializer(0, 0.02)) (input_layer)\n",
    "    concat1 = concatenate([upconv1, skip_layer])\n",
    "    conv1 = Conv2D(output_channels, kernel_size, activation='relu', padding='same',\\\n",
    "                   kernel_initializer=tf.random_normal_initializer(0, 0.02)) (concat1)\n",
    "    return conv1\n",
    "\n",
    "def create_unet(input_shape=(240,240,1), num_classes=4):\n",
    "    inputs_coarse = Input(input_shape)\n",
    "\n",
    "    encoding_layer1=encoding_layer(inputs_coarse,64,3)\n",
    "    pool1 = MaxPooling2D((2, 2),padding='same') (encoding_layer1)\n",
    "    encoding_layer2=encoding_layer(pool1,128,3)\n",
    "    pool2 = MaxPooling2D((2, 2),padding='same') (encoding_layer2)\n",
    "    encoding_layer3=encoding_layer(pool2,256,3)\n",
    "    pool3 = MaxPooling2D((2, 2),padding='same') (encoding_layer3)\n",
    "    encoding_layer4=encoding_layer(pool3,512,3)\n",
    "    pool4 = MaxPooling2D((2, 2),padding='same') (encoding_layer4)\n",
    "\n",
    "    bottleneck=bottleneck(pool4,1024,3)\n",
    "\n",
    "    decoding_layer1= decoding_layer(bottleneck,encoding_layer4,512,3,1)\n",
    "    decoding_layer2= decoding_layer(decoding_layer1,encoding_layer3,256,3,1)\n",
    "    decoding_layer3 = decoding_layer(decoding_layer2,encoding_layer2,128,3,2)\n",
    "    decoding_layer4 = decoding_layer(decoding_layer3,encoding_layer1,64,3,2)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax') (decoding_layer4)\n",
    "\n",
    "    model = Model(inputs=inputs_coarse, outputs=[outputs])\n",
    "    optim=Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optim, loss=['sparse_categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862d0d1",
   "metadata": {},
   "source": [
    "### Training avec Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer dans un terminal la commande: tensorboard --logdir \"./logs\"\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_unet()\n",
    "tensorboard_callback_unet = TensorBoard(log_dir=os.path.expanduser(\"~CV_project_MRI/logs/unet\"))\n",
    "\n",
    "# Creation du dataset\n",
    "\n",
    "## Créer les paires\n",
    "data = list(zip(X_paths, Y_paths))\n",
    "random.shuffle(data)\n",
    "\n",
    "## Split Dataset Train, Val, Test\n",
    "n = len(data)\n",
    "train_data = data[:int(0.7*n)]\n",
    "val_data   = data[int(0.7*n):int(0.9*n)]\n",
    "test_data  = data[int(0.9*n):]\n",
    "\n",
    "train_ds = make_dataset(train_data, batch_size=BATCH_SIZE)\n",
    "val_ds   = make_dataset(val_data, batch_size=BATCH_SIZE)\n",
    "test_ds  = make_dataset(test_data, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e161ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[\n",
    "        tensorboard_callback_unet, \n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"checkpoints/unet_best.h5\", monitor='val_loss', save_best_only=True)\n",
    "        ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8504ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
